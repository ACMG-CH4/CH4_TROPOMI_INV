#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import glob
import numpy as np
from netCDF4 import Dataset
import xarray as xr
import pickle

def save_obj(obj, name ):
    """ Save something with Pickle. """

    with open(name , 'wb') as f:
        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)


def load_obj(name):
    """ Load something with Pickle. """

    with open(name, 'rb') as f:
        return pickle.load(f)


def do_inversion(n_elements, jacobian_dir, lon_min, lon_max, lat_min, lat_max, prior_err=0.5, obs_err=15, gamma=0.25, res='0.25x0.3125'):
    '''
    After running jacobian.py, use this script to perform the inversion and save out results.

    Arguments
        n_elements   [int]   : Number of state vector elements
        jacobian_dir [str]   : Directory where the data from jacobian.py are stored
        lon_min      [float] : Minimum longitude
        lon_max      [float] : Maximum longitude
        lat_min      [float] : Minimum latitude
        lat_max      [float] : Maximum latitude
        prior_err    [float] : Prior error standard deviation (default 0.5)
        obs_err      [float] : Observational error standard deviation (default 15 ppb)
        gamma        [float] : Regularization parameter (default 0.25)

    Returns
        xhat         [float] : Posterior scaling factors
        ratio        [float] : Change from prior     [xhat = 1 + ratio]
        all_part1    [float] : K^T*inv(S_o)*K        [part of inversion equation]
        all_part2    [float] : K^T*inv(S_o)*(y-K*xA) [part of inversion equation]

    '''

    # Need to ignore data in the GEOS-Chem buffer zone
    # Shave off one or two degrees of latitude/longitude from each side of the domain
    # 1 degree if 0.25x0.3125 resolution, 2 degrees if 0.5x0.6125 resolution
    if '0.25x0.3125' in res:
        deg = 1
    elif '0.5x0.625' in res:
        deg = 2
    else:
        msg = "Bad input for res; must be '0.25x0.3125' or '0.5x0.625' "
        raise ValueError(msg)
        
    xlim = [lon_min+deg, lon_max-deg]
    ylim = [lat_min+deg, lat_max-deg]

    # Read output data from jacobian.py (virtual & true TROPOMI columns, Jacobian matrix)
    files = glob.glob(f'{jacobian_dir}/*.pkl')
    files.sort()

    # ==========================================================================================
    # Now we will assemble different terms of the analytical inversion.
    #
    # These are the terms of eq. (5) and (6) in Zhang et al. (2018) ACP:
    # "Monitoring global OH concentrations using satellite observations of atmospheric methane".
    #
    # Specifically, we are going to solve:
    #   xhat = xA + G*(y-K*xA) 
    #        = xA + inv(gamma*K^T*inv(S_o)*K + inv(S_a)) * gamma*K^T*inv(S_o) * (y-K*xA)
    #
    # In the code below this becomes
    #   xhat = xA + inv(gamma*all_part1 + inv(S_a)) * gamma*all_part2
    #        = xA + ratio
    #        = 1  + ratio      [since xA=1 when optimizing scale factors]
    # ==========================================================================================

    # Initialize two parts of the inversion equation
    all_part1 = np.zeros([n_elements,n_elements], dtype=float)
    all_part2 = np.zeros([n_elements], dtype=float)

    # For each .pkl file generated by jacobian.py:
    for fi in files:
        
        print(fi)

        # Load TROPOMI/GEOS-Chem and Jacobian matrix data from the .pkl file
        dat = load_obj(fi)

        # If there aren't any TROPOMI observations on this day, skip 
        if dat['obs_GC'].shape[0] == 0:
            continue

        # Otherwise, grab the TROPOMI/GEOS-Chem data
        obs_GC = dat['obs_GC']
        
        # Only consider data within the new latitude and longitude bounds
        ind = np.where((obs_GC[:,2]>=xlim[0]) & (obs_GC[:,2]<=xlim[1]) & 
                       (obs_GC[:,3]>=ylim[0]) & (obs_GC[:,3]<=ylim[1]))[0]

        # Skip if no data in bounds
        if (len(ind) == 0):
            continue

        # TROPOMI and GEOS-Chem data within bounds
        obs_GC = obs_GC[ind,:]

        # Jacobian entries for observations within bounds [ppb]
        K = 1e9 * dat['KK'][ind,:]

        # Number of observations
        N = obs_GC.shape[0]
        print('Sum of Jacobian entries:', np.sum(K))

        # Define observational errors (diagonal entries of S_o matrix)
        obs_error = np.zeros(N)
        obs_error.fill(obs_err**2)
    
        # Measurement-model mismatch: TROPOMI columns minus GEOS-Chem virtual TROPOMI columns
        # This is (y - F(xA)), or (y - (K*xA + O)), or (y - K*xA) in shorthand
        deltaY = obs_GC[:,0] - obs_GC[:,1] # [ppb]
        
        # If there are any nan's in the data, abort 
        if (np.any(np.isnan(deltaY)) or np.any(np.isnan(K)) or np.any(np.isnan(obs_error))):
            print('missing values', fi)
            break
    
        # Define KT_invSo = K^T*inv(S_o)
        KT = K.transpose() 
        KT_invSo = np.zeros(KT.shape, dtype=float)
        for k in range(KT.shape[1]):
            KT_invSo[:,k] = KT[:,k]/obs_error[k]        

        # Parts of inversion equation
        part1 = KT_invSo@K             # K^T*inv(S_o)*K
        part2 = KT_invSo@deltaY        # K^T*inv(S_o)*(y-K*xA)
   
        # Add part1 & part2 to sums 
        all_part1 += part1
        all_part2 += part2
        
    # Inverse of prior error covariance matrix, inv(S_a)
    emis_error = np.zeros(n_elements)
    emis_error.fill(prior_err**2)    
    inv_Sa = np.diag(1/emis_error)   # Inverse of prior error covariance matrix

    # Solve for posterior scaling factors, xhat
    ratio = np.linalg.inv(gamma*all_part1 + inv_Sa)@(gamma*all_part2)
    xhat = 1 + ratio

    # Posterior error covariance matrix
    S_post = np.linalg.inv(gamma*all_part1 + inv_Sa)

    # Averaging kernel matrix
    A = np.identity(n_elements) - S_post@inv_Sa


    return xhat, ratio, all_part1, all_part2, S_post, A


if __name__ == '__main__':
    import sys

    n_elements = int(sys.argv[1])
    jacobian_dir = sys.argv[2]
    output_path = sys.argv[3]
    lon_min = float(sys.argv[4])
    lon_max = float(sys.argv[5])
    lat_min = float(sys.argv[6])
    lat_max = float(sys.argv[7])
    prior_err = float(sys.argv[8])
    obs_err = float(sys.argv[9])
    gamma = float(sys.argv[10])
    res = sys.argv[11]

    # Run the inversion code
    out = do_inversion(n_elements, jacobian_dir, lon_min, lon_max, lat_min, lat_max, prior_err, obs_err, gamma, res)
    xhat = out[0]
    ratio = out[1]
    all_part1 = out[2]
    all_part2 = out[3]
    S_post = out[4]
    A = out[5]

    # Print some statistics
    print('Min:', xhat.min(), 'Mean:', xhat.mean(), 'Max', xhat.max())

    # Save results
    dataset = Dataset(output_path, 'w', format='NETCDF4_CLASSIC')
    nvar = dataset.createDimension('nvar', n_elements)
    nc_all_part1 = dataset.createVariable('all_part1', np.float32,('nvar','nvar'))
    nc_all_part2 = dataset.createVariable('all_part2', np.float32,('nvar'))
    nc_ratio = dataset.createVariable('ratio', np.float32,('nvar'))
    nc_xhat = dataset.createVariable('xhat', np.float32, ('nvar'))
    nc_S_post = dataset.createVariable('S_post', np.float32,('nvar','nvar'))
    nc_A = dataset.createVariable('A', np.float32,('nvar','nvar'))
    nc_all_part1[:,:] = all_part1
    nc_all_part2[:] = all_part2
    nc_ratio[:] = ratio
    nc_xhat[:] = xhat
    nc_S_post[:,:] = S_post
    nc_A[:,:] = A
    dataset.close()

    print(f'Saved results to {output_path}')
